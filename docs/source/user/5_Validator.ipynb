{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stainless-sweden",
   "metadata": {},
   "source": [
    "# Validator\n",
    "`Validator` verifies the quality of samples generated by `Transformation` and `AttackRecipe`. Here we briefly describe how to use the built-in `Validator`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the built-in Validator `SentenceEncoding`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from TextFlint.generation_layer.validator.sentence_encoding import SentenceEncoding\n",
    "from TextFlint.input_layer.dataset.dataset import Dataset\n",
    "from TextFlint.input_layer.component.sample.sa_sample import SASample\n",
    "\n",
    "\n",
    "# 1. Define an original sentence.\n",
    "ori_sentence = 'There is a book on the desk .'\n",
    "ori_sample = SASample({'x': ori_sentence, 'y': '1'})\n",
    "\n",
    "# 2. Define some transformed sentence randomly.\n",
    "trans_sentences = ['There is a book on the desk .',\n",
    "                   'There is a book on the floor .',\n",
    "                   'There is a cookie on the desk .',\n",
    "                   'There is a desk on the book .',\n",
    "                   'There desk a on the is a book .']\n",
    "\n",
    "# 3. Feed the sample to Dataset \n",
    "ori_dataset = Dataset('SA')\n",
    "trans_dataset = Dataset('SA')\n",
    "ori_dataset.append(ori_sample, sample_id=0)\n",
    "for trans_sentence in trans_sentences:\n",
    "    trans_dataset.append(\n",
    "        SASample({'x': trans_sentence, 'y': '1'}), sample_id=0)\n",
    "\n",
    "# 4. Run the SentenceEncoding Validator\n",
    "score = SentenceEncoding(ori_dataset, trans_dataset, 'x').score\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the `SentenceEncoding` to validate `BreadWordSwap`\n",
    "Recall that we defined a `Transformation` `BreadWordSwap` in the transformation tutorial, and here we can use `SentenceEncoding` to simply test whether the tranformed data is semantically smooth. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from TextFlint.generation_layer.transformation import WordSubstitute\n",
    "\n",
    "class BreadWordSwap(WordSubstitute):\n",
    "    r\"\"\"\n",
    "    Word Swap by randomly swaping words with bread.\n",
    "\n",
    "    \"\"\"\n",
    "    def _get_candidates(self, word, pos=None, n=1):\n",
    "        r\"\"\"\n",
    "        Returns a list containing apple.\n",
    "\n",
    "        :param word: str, the word to replace\n",
    "        :param pos: str, the pos of the word to replace\n",
    "        :param n: the number of returned words\n",
    "        :return: a candidates list\n",
    "        \"\"\"\n",
    "        return ['bread']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's first look at the semantic fluidity by replacing **one** word to `bread`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans = BreadWordSwap(trans_min=1) # swap 1 word\n",
    "trans_sample = trans.transform(ori_sample)\n",
    "print(trans_sample[0].dump())\n",
    "\n",
    "trans_dataset = Dataset('SA')\n",
    "trans_dataset.append(trans_sample[0])\n",
    "score = SentenceEncoding(ori_dataset, trans_dataset, 'x').score\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we further take a look at the semantic fluidity by replacing `three` words:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans = BreadWordSwap(trans_min=3) # swap 3 word\n",
    "trans_sample = trans.transform(ori_sample)\n",
    "print(trans_sample[0].dump())\n",
    "\n",
    "trans_dataset = Dataset('SA')\n",
    "trans_dataset.append(trans_sample[0])\n",
    "score = SentenceEncoding(ori_dataset, trans_dataset, 'x').score\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "In this tutorial, we show that semantic fluency becomes lower when the number of substitution words becomes more numerous, which explains the need of using `Validator` to filter lower score samples. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}